# Procesamiento de Im√°genes SAR para Detecci√≥n de Erosi√≥n Costera

Proyecto desarrollado para el curso **"Python para HPC - Introducci√≥n a la programaci√≥n HPC con Python y sus aplicaciones al campo de proceso de im√°genes"**.

Este repositorio implementa y compara diferentes t√©cnicas de procesamiento paralelo aplicadas al an√°lisis de im√°genes SAR (Synthetic Aperture Radar) para la detecci√≥n y monitoreo de erosi√≥n costera.

---

## üìã Descripci√≥n del proyecto

El proyecto implementa un pipeline completo de procesamiento de im√°genes SAR que incluye:
- Filtrado de ruido speckle
- Mejora de contraste (CLAHE/Ecualizaci√≥n)
- Detecci√≥n de bordes (Sobel/Canny)
- Segmentaci√≥n tierra/agua (Otsu + morfolog√≠a)
- Extracci√≥n de l√≠nea de costa
- An√°lisis de textura (varianza local)

### T√©cnicas de paralelizaci√≥n implementadas

1. **Secuencial OpenCV**: Implementaci√≥n base sin paralelizaci√≥n
2. **Multiprocessing Pool**: Paralelizaci√≥n CPU usando m√∫ltiples procesos
3. **ThreadPoolExecutor**: Paralelizaci√≥n CPU usando hilos
4. **MPI (Message Passing Interface)**: Procesamiento distribuido con MPI4Py
5. **CuPy GPU**: Aceleraci√≥n mediante procesamiento en GPU con CUDA

---

## üõ∞Ô∏è Fuente de datos

### Dataset de im√°genes SAR de Alaska

Las im√°genes utilizadas en este proyecto provienen del producto **ORI (Orthorectified Radar Image)** de **Intermap Technologies**, obtenidas a trav√©s del portal **EarthExplorer** del Servicio Geol√≥gico de Estados Unidos (USGS). Los datos fueron adquiridos mediante el sistema aerotransportado **STAR-3** de Radar de Apertura Sint√©tica Interferom√©trico (IFSAR) sobre Alaska, entre el 23 de agosto y el 6 de septiembre de 2012.

#### Especificaciones de los datos originales

| Par√°metro | Valor |
|-----------|-------|
| **Fuente** | USGS EarthExplorer - IFSAR ORI Alaska |
| **Producto** | Orthorectified Radar Image (ORI) |
| **Tecnolog√≠a** | Interferometric Synthetic Aperture Radar (IFSAR) |
| **Sensor** | STAR-3 (aerotransportado) |
| **Resoluci√≥n espacial** | 0.625 metros |
| **Formato original** | GeoTIFF de 8 bits |
| **Dimensiones originales** | ~23,344 √ó 46,728 p√≠xeles |
| **Tama√±o por archivo** | ~1 GB |
| **Sistema de coordenadas** | Albers Conical Equal Area (NAD83 CORS96) |
| **√Årea de cobertura** | Alaska, USA |
| **Per√≠odo de adquisici√≥n** | 23 de agosto - 6 de septiembre de 2012 |
| **Total de im√°genes** | 50 |

#### Procesamiento aplicado al dataset

Las im√°genes originales fueron procesadas para optimizar su almacenamiento y uso en aplicaciones de procesamiento paralelo, reduciendo sus dimensiones mediante reescalado:

- **Dimensiones procesadas:** 2,000 √ó 4,000 p√≠xeles
- **Factor de reducci√≥n:** ~11.7√ó en ancho, ~11.7√ó en alto
- **Proporci√≥n de aspecto:** Mantenida (1:2 aproximadamente)
- **Formato:** GeoTIFF de 8 bits

Esta reducci√≥n permiti√≥ generar un dataset m√°s manejable (de ~1 GB a ~80 MB por imagen) manteniendo las caracter√≠sticas espaciales relevantes de las im√°genes radar para el an√°lisis de erosi√≥n costera.

#### Cita recomendada

```
Intermap Technologies Inc. (2012). IFSAR ORI Alaska - Orthorectified Radar Images.
Obtenido de USGS EarthExplorer. Datos de adquisici√≥n: Agosto-Septiembre 2012.
Accedido: [fecha de descarga].
```

#### Descarga del dataset

El dataset preprocesado (50 im√°genes, 2000√ó4000 px) se descarga autom√°ticamente al ejecutar:

```bash
make download-dataset
```

Las im√°genes se almacenar√°n en el directorio `dataset/` en formato PNG.

---

## üöÄ Instalaci√≥n y configuraci√≥n

### 1. Clonar el repositorio

```bash
git clone https://github.com/jorgeceferinovaldez/parallel-sar-processor.git
cd parallel-sar-processor
```

### 2. Crear entorno Conda con Python 3.11

```bash
# Crear entorno conda con Python 3.11
conda create -n parallel-sar-processor python=3.11

# Activar el entorno
conda activate parallel-sar-processor
```

### 3. Instalar dependencias

#### Instalaci√≥n B√°sica (CPU)

```bash
make install
```

Este comando instalar√° las siguientes dependencias principales:
- OpenCV (procesamiento de im√°genes)
- NumPy (arrays y operaciones num√©ricas)
- Pandas (an√°lisis de datos)
- Matplotlib/Seaborn (visualizaci√≥n)
- MPI4Py (procesamiento distribuido)
- CuPy (procesamiento GPU - requiere CUDA)
- gdown (descarga de datasets)

#### Instalaci√≥n para desarrollo (Opcional)

```bash
make install-dev
```

Incluye herramientas adicionales:
- Testing (pytest, pytest-cov)
- Formateo (black, isort)
- Linting (flake8, pylint)
- Type checking (mypy)
- Jupyter notebooks
- Profiling (line-profiler, memory-profiler)

### 4. Requisitos del sistema

#### MPI
Para usar el procesamiento con MPI, necesitas tener instalado `mpiexec` o `mpirun`:

**Ubuntu/Debian:**
```bash
sudo apt-get install openmpi-bin libopenmpi-dev
```

**Fedora/RHEL:**
```bash
sudo dnf install openmpi openmpi-devel
```

#### CUDA Toolkit 12.x (requerido para CuPy GPU)

**IMPORTANTE**: CuPy requiere el CUDA Toolkit completo instalado y configurado en el sistema para tener soporte de GPU. Sin CUDA Toolkit, CuPy no funcionar√°.

**Requisitos:**
- GPU NVIDIA compatible con CUDA (Compute Capability ‚â• 3.5)
- Driver NVIDIA actualizado (versi√≥n ‚â• 525.60.13 para CUDA 12.x)
- CUDA Toolkit 12.x completo

##### Opci√≥n 1: Instalaci√≥n de CUDA Toolkit mediante Conda (recomendado)

La forma m√°s sencilla y segura es instalar CUDA Toolkit directamente en el entorno conda:

```bash
# Activar el entorno
conda activate parallel-sar-processor

# Instalar CUDA Toolkit 12.x completo en el entorno conda
conda install -c nvidia cuda-toolkit=12.6

# Instalar cudnn (opcional pero recomendado para mejor rendimiento)
conda install -c conda-forge cudnn

# Verificar la instalaci√≥n
nvcc --version
```

**Ventajas de usar Conda:**
- ‚úÖ No requiere permisos de administrador
- ‚úÖ Aislado en el entorno virtual (no afecta el sistema)
- ‚úÖ F√°cil de desinstalar o actualizar
- ‚úÖ Compatible con m√∫ltiples versiones de CUDA en diferentes entornos
- ‚úÖ Instalaci√≥n autom√°tica de todas las dependencias

##### Opci√≥n 2: Instalaci√≥n de CUDA Toolkit a nivel de sistema

Si prefieres instalar CUDA a nivel de sistema (requiere permisos sudo):

**Ubuntu/Debian:**
```bash
# Descargar e instalar CUDA Toolkit 12.6
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get install cuda-toolkit-12-6

# Configurar variables de entorno (agregar a ~/.bashrc)
export PATH=/usr/local/cuda-12.6/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-12.6/lib64:$LD_LIBRARY_PATH

# Recargar configuraci√≥n
source ~/.bashrc
```

**Fedora/RHEL:**
```bash
# Descargar e instalar CUDA Toolkit 12.6
sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/cuda-rhel9.repo
sudo dnf clean all
sudo dnf install cuda-toolkit-12-6

# Configurar variables de entorno
export PATH=/usr/local/cuda-12.6/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-12.6/lib64:$LD_LIBRARY_PATH
```

##### Verificar instalaci√≥n de CUDA y driver NVIDIA

```bash
# Verificar versi√≥n de CUDA Toolkit instalado
nvcc --version

# Verificar driver NVIDIA y GPUs disponibles
nvidia-smi

# Verificar que CuPy detecta la GPU (despu√©s de instalar dependencias)
python -c "import cupy as cp; print(f'CuPy version: {cp.__version__}'); print(f'CUDA version: {cp.cuda.runtime.runtimeGetVersion()}'); print(f'Device: {cp.cuda.Device(0).compute_capability}')"
```

**Salida esperada de `nvidia-smi`:**
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03   Driver Version: 535.129.03   CUDA Version: 12.2   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
...
```

**Notas importantes:**
- Si no tienes GPU NVIDIA, el proyecto funcionar√° igualmente con las t√©cnicas CPU (OpenCV, Pool, Thread, MPI)
- La versi√≥n de CuPy en `requirements.txt` es `cupy-cuda12x`, compatible con CUDA 12.0-12.6
- Para otras versiones de CUDA, instala el paquete CuPy correspondiente:
  - CUDA 11.x: `cupy-cuda11x`
  - CUDA 12.x: `cupy-cuda12x`

### 5. Verificar instalaci√≥n

```bash
make check
```

Este comando verificar√°:
- ‚úÖ Python instalado correctamente
- ‚úÖ MPI disponible
- ‚úÖ CUDA Toolkit (si est√° instalado)
- ‚úÖ CuPy funcionando con GPU

---

## üì¶ Comandos make disponibles

El proyecto utiliza un `Makefile` para automatizar todas las tareas. A continuaci√≥n se describen los comandos disponibles:

### Comandos de configuraci√≥n

| Comando | Descripci√≥n |
|---------|-------------|
| `make help` | Muestra la ayuda con todos los comandos disponibles |
| `make setup` | Configuraci√≥n inicial completa (install + check) |
| `make install` | Instala dependencias de producci√≥n desde `requirements.txt` |
| `make install-dev` | Instala dependencias de desarrollo desde `requirements-dev.txt` |
| `make check` | Verifica requisitos del sistema (Python, MPI, CUDA, CuPy) |

### Comandos de procesamiento

| Comando | Descripci√≥n |
|---------|-------------|
| `make download-dataset` | Descarga el dataset de im√°genes SAR desde Google Drive |
| `make MPI` | Ejecuta procesamiento con MPI (12 procesos por defecto) |
| `make parallel` | Ejecuta procesamiento con t√©cnicas paralelas (Pool, Thread, CuPy) |
| `make comparacion` | Genera gr√°ficos y resumen comparativo de todas las t√©cnicas |
| `make pipeline` | Ejecuta el pipeline completo (download + MPI + parallel + comparacion) |

### Comandos auxiliares

| Comando | Descripci√≥n |
|---------|-------------|
| `make clean` | Limpia archivos generados (output/*, __pycache__, etc.) |
| `make procesamiento` | Ejecuta solo MPI + parallel (sin descarga ni comparaci√≥n) |
| `make run-mpi NPROCS=8` | Ejecuta MPI con n√∫mero personalizado de procesos |

---

## üéØ Flujo de trabajo t√≠pico

### Ejecuci√≥n completa del pipeline

```bash
# 1. Configuraci√≥n inicial (solo primera vez)
make setup

# 2. Ejecutar pipeline completo
make pipeline
```

El comando `make pipeline` ejecutar√° secuencialmente:
1. Descarga del dataset
2. Procesamiento MPI
3. Procesamiento paralelo (Pool, Thread, CuPy)
4. Generaci√≥n de gr√°ficos comparativos

### Ejecuci√≥n paso a paso

```bash
# 1. Descargar dataset
make download-dataset

# 2. Procesar con MPI
make MPI

# 3. Procesar con t√©cnicas paralelas
make parallel

# 4. Generar comparaci√≥n
make comparacion
```

### Personalizar n√∫mero de procesos MPI

Por defecto se utilizan 12 procesos. Para cambiar este valor:

```bash
# Temporal (para una ejecuci√≥n)
make run-mpi NPROCS=8

# Permanente (editar Makefile)
# Cambiar la l√≠nea: MPI_PROCESSES := 12
```

---

## üìä Resultados y salidas

### Estructura de directorios de salida

Al ejecutar el pipeline o los comandos de descarga/procesamiento, se generar√°n autom√°ticamente los siguientes directorios:

```
dataset/                 # [CREADO EN DESCARGA] Im√°genes SAR Reescaaladas manteniendo proporciones
‚îú‚îÄ‚îÄ imagen_001.png       # Imagen SAR 1 (2000x4000 p√≠xeles)
‚îú‚îÄ‚îÄ imagen_002.png       # Imagen SAR 2
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ imagen_050.png       # Imagen SAR 50
                         # Total: 50 im√°genes IFSAR ORI de Alaska

output/                  # [CREADO EN PROCESAMIENTO] Resultados por t√©cnica
‚îú‚îÄ‚îÄ sar_opencv/          # Resultados procesamiento secuencial
‚îú‚îÄ‚îÄ sar_pool/            # Resultados multiprocessing Pool
‚îú‚îÄ‚îÄ sar_thread/          # Resultados ThreadPoolExecutor
‚îú‚îÄ‚îÄ sar_mpi/             # Resultados MPI
‚îî‚îÄ‚îÄ sar_cupy_gpu/        # Resultados CuPy GPU

metrics/                 # [CREADO EN PROCESAMIENTO] M√©tricas CSV
‚îú‚îÄ‚îÄ metricas_tecnicas_sar.csv              # M√©tricas de t√©cnicas paralelas
‚îú‚îÄ‚îÄ metricas_tecnica_mpi.csv               # M√©tricas de MPI
‚îú‚îÄ‚îÄ metricas_procesos_mpi.csv              # M√©tricas por proceso MPI
‚îú‚îÄ‚îÄ metricas_imagenes_opencv.csv           # M√©tricas por imagen (OpenCV)
‚îú‚îÄ‚îÄ metricas_imagenes_pool.csv             # M√©tricas por imagen (Pool)
‚îú‚îÄ‚îÄ metricas_imagenes_thread.csv           # M√©tricas por imagen (Thread)
‚îú‚îÄ‚îÄ metricas_imagenes_mpi.csv              # M√©tricas por imagen (MPI)
‚îî‚îÄ‚îÄ metricas_imagenes_cupy.csv             # M√©tricas por imagen (CuPy)

summary/                 # [CREADO EN COMPARACI√ìN] Resumen y gr√°ficos
‚îú‚îÄ‚îÄ comparacion_tecnicas_sar.png           # Gr√°ficos comparativos
‚îú‚îÄ‚îÄ informe_final_sar.txt                  # Informe textual
‚îî‚îÄ‚îÄ metricas_todas_tecnicas_completo.csv   # Tabla comparativa completa
```

### Im√°genes generadas por t√©cnica

Para cada imagen SAR procesada se generan 5 salidas:

1. **enhanced.png**: Imagen con contraste mejorado (post-CLAHE/ecualizaci√≥n)
2. **edges.png**: Mapa de detecci√≥n de bordes (Sobel)
3. **segmentation.png**: Segmentaci√≥n binaria tierra/agua
4. **coastline.png**: L√≠nea de costa extra√≠da
5. **texture.png**: Mapa de an√°lisis de textura (varianza local)

### M√©tricas calculadas

Para cada imagen se calculan las siguientes m√©tricas:

| M√©trica | Descripci√≥n |
|---------|-------------|
| `intensidad_media` | Intensidad promedio de la imagen mejorada |
| `intensidad_std` | Desviaci√≥n est√°ndar de la intensidad |
| `num_bordes_canny` | N√∫mero de p√≠xeles de bordes detectados (Canny) |
| `intensidad_gradiente_media` | Intensidad promedio del gradiente (Sobel) |
| `porcentaje_tierra` | Porcentaje de p√≠xeles clasificados como tierra |
| `porcentaje_agua` | Porcentaje de p√≠xeles clasificados como agua |
| `num_contornos_costa` | N√∫mero de contornos de l√≠nea de costa detectados |
| `longitud_costa_px` | Longitud total de la l√≠nea de costa en p√≠xeles |
| `rugosidad_media` | Rugosidad/variaci√≥n de textura promedio |

---

## üîÑ Diagrama de flujo de procesamiento

El siguiente diagrama muestra el pipeline de procesamiento aplicado a cada imagen:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PIPELINE DE PROCESAMIENTO SAR                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Imagen SAR     ‚îÇ  Entrada: Imagen en formato TIFF/PNG/JPG
‚îÇ  (Original)     ‚îÇ  Ejemplo: imagen_costera_001.tif
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. CARGA Y      ‚îÇ  ‚Ä¢ Lectura en escala de grises
‚îÇ    REDIMENSI√ìN  ‚îÇ  ‚Ä¢ Redimensi√≥n a 1000x2000 p√≠xeles (ancho x alto)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚Ä¢ Normalizaci√≥n de valores 0-255
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. FILTRADO     ‚îÇ  ‚Ä¢ Filtro bilateral (reducci√≥n ruido speckle)
‚îÇ    DE RUIDO     ‚îÇ  ‚Ä¢ Non-Local Means Denoising
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚Ä¢ Preservaci√≥n de bordes
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. MEJORA DE    ‚îÇ  ‚Ä¢ OpenCV/Pool/Thread/MPI: CLAHE (Contrast Limited AHE)
‚îÇ    CONTRASTE    ‚îÇ  ‚Ä¢ CuPy GPU: Ecualizaci√≥n de histograma en GPU
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚Üí Salida: enhanced.png
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                                             ‚îÇ
         ‚ñº                                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. DETECCI√ìN    ‚îÇ                          ‚îÇ 5. SEGMENTACI√ìN ‚îÇ
‚îÇ    DE BORDES    ‚îÇ                          ‚îÇ    TIERRA/AGUA  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                          ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Canny (CPU)   ‚îÇ                          ‚îÇ ‚Ä¢ Umbralizaci√≥n ‚îÇ
‚îÇ ‚Ä¢ Sobel X/Y     ‚îÇ                          ‚îÇ   Otsu          ‚îÇ
‚îÇ ‚Ä¢ Magnitud de   ‚îÇ                          ‚îÇ ‚Ä¢ Morfolog√≠a    ‚îÇ
‚îÇ   gradiente     ‚îÇ                          ‚îÇ   (cierre +     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ    apertura)    ‚îÇ
         ‚îÇ                                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                                            ‚îÇ
         ‚ñº                                            ‚ñº
    edges.png                               segmentation.png
         ‚îÇ                                            ‚îÇ
         ‚îÇ                                            ‚ñº
         ‚îÇ                                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                                   ‚îÇ 6. EXTRACCI√ìN   ‚îÇ
         ‚îÇ                                   ‚îÇ    L√çNEA COSTA  ‚îÇ
         ‚îÇ                                   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
         ‚îÇ                                   ‚îÇ ‚Ä¢ Detecci√≥n de  ‚îÇ
         ‚îÇ                                   ‚îÇ   contornos     ‚îÇ
         ‚îÇ                                   ‚îÇ ‚Ä¢ Filtrado por  ‚îÇ
         ‚îÇ                                   ‚îÇ   √°rea >1000px  ‚îÇ
         ‚îÇ                                   ‚îÇ ‚Ä¢ C√°lculo de    ‚îÇ
         ‚îÇ                                   ‚îÇ   longitud      ‚îÇ
         ‚îÇ                                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                                            ‚îÇ
         ‚îÇ                                            ‚ñº
         ‚îÇ                                      coastline.png
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 7. AN√ÅLISIS     ‚îÇ  ‚Ä¢ Filtrado de varianza local (ventana 15x15)
‚îÇ    DE TEXTURA   ‚îÇ  ‚Ä¢ C√°lculo de rugosidad
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚Ä¢ Identificaci√≥n de zonas de alta variabilidad
         ‚îÇ
         ‚ñº
    texture.png
         ‚îÇ
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 8. C√ÅLCULO DE   ‚îÇ  ‚Ä¢ intensidad_media, intensidad_std
‚îÇ    M√âTRICAS     ‚îÇ  ‚Ä¢ num_bordes, intensidad_gradiente_media
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚Ä¢ % tierra/agua, num_contornos, longitud_costa
         ‚îÇ            ‚Ä¢ rugosidad_media
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SALIDA FINAL   ‚îÇ  5 im√°genes procesadas + 9 m√©tricas por imagen
‚îÇ  (5 im√°genes +  ‚îÇ
‚îÇ   m√©tricas CSV) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

NOTAS:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚Ä¢ Todas las t√©cnicas (OpenCV, Pool, Thread, MPI, CuPy) siguen el mismo pipeline
‚Ä¢ La diferencia est√° en c√≥mo se paraleliza el procesamiento de m√∫ltiples im√°genes
‚Ä¢ CuPy ejecuta las operaciones 1-7 en GPU, luego transfiere a CPU para paso 8
‚Ä¢ MPI distribuye las im√°genes entre m√∫ltiples procesos de forma c√≠clica
‚Ä¢ Pool/Thread procesan m√∫ltiples im√°genes en paralelo usando cores CPU
```

---

## üß™ Descripci√≥n de scripts principales

### `download_dataset.py`
Descarga autom√°ticamente el dataset de im√°genes SAR desde Google Drive.

**Funcionalidad:**
- Descarga archivo ZIP desde Google Drive
- Descomprime en directorio `dataset/`
- Limpia archivo temporal

### `coastal_SAR_parallel.py`
Implementa y compara tres t√©cnicas de paralelizaci√≥n CPU + GPU:

**T√©cnicas implementadas:**
1. **Secuencial OpenCV**: Baseline sin paralelizaci√≥n
2. **Multiprocessing Pool**: `multiprocessing.Pool` con N procesos
3. **ThreadPoolExecutor**: `concurrent.futures.ThreadPoolExecutor`
4. **CuPy GPU**: Procesamiento acelerado en GPU

**Salidas:**
- Im√°genes procesadas en `output/sar_{tecnica}/`
- M√©tricas en `metrics/metricas_{tecnica}.csv`

### `coastal_SAR_MPI.py`
Implementa procesamiento distribuido usando MPI4Py.

**Caracter√≠sticas:**
- Distribuci√≥n c√≠clica de im√°genes entre procesos
- Proceso maestro (rank 0) coordina y recopila resultados
- Sincronizaci√≥n con barreras MPI
- C√°lculo de eficiencia y balance de carga

**Salidas:**
- Im√°genes procesadas en `output/sar_mpi/`
- M√©tricas por proceso y globales en `metrics/`

### `graph_comparison.py`
Genera visualizaciones y resumen comparativo de todas las t√©cnicas.

**Gr√°ficos generados:**
1. Tiempo total de procesamiento
2. Speedup vs secuencial
3. Throughput (img/s)
4. Comparaci√≥n de m√©tricas de imagen (intensidad, segmentaci√≥n, etc.)
5. Tabla comparativa completa

**Salidas:**
- `summary/comparacion_tecnicas_sar.png`
- `summary/informe_final_sar.txt`
- `summary/metricas_todas_tecnicas_completo.csv`

### `tools_img.py`
M√≥dulo con la funci√≥n principal de procesamiento SAR usando OpenCV.

**Funci√≥n principal:**
```python
procesar_imagen_sar_costera(
    ruta_entrada: str,
    carpeta_salida: str,
    nombre_base: str,
    tamanio_fijo: tuple = (1000, 2000)
) -> dict
```

### `tools_cupy.py`
M√≥dulo con la funci√≥n de procesamiento SAR acelerado en GPU.

**Funci√≥n principal:**
```python
procesar_imagen_sar_gpu(
    ruta_entrada: str,
    carpeta_salida: str,
    nombre_base: str,
    tamanio_fijo: tuple = (1000, 2000)
) -> dict
```

**Caracter√≠sticas:**
- Transferencia de datos CPU ‚Üí GPU
- Operaciones en GPU con CuPy
- Sincronizaci√≥n y liberaci√≥n de memoria GPU
- Transferencia de resultados GPU ‚Üí CPU

---

## üîß Personalizaci√≥n

### Cambiar n√∫mero de procesos/hilos

**En el Makefile (MPI):**
```makefile
MPI_PROCESSES := 12  # Cambiar este valor
```

**En `coastal_SAR_parallel.py`:**
```python
P = mp.cpu_count()              # Pool: todos los cores
num_hilos = P                   # Thread: todos los hilos
```

### Cambiar tama√±o de imagen procesada

En los scripts de procesamiento:
```python
tamanio_fijo = (1000, 2000)  # (ancho, alto) en p√≠xeles
```

### Agregar nuevas m√©tricas

1. Modificar funci√≥n `procesar_imagen_sar_costera()` en `tools_img.py`
2. Agregar c√°lculo de nueva m√©trica en el diccionario `metricas`
3. Actualizar `graph_comparison.py` para visualizar la nueva m√©trica

---

## üìà Resultados obtenidos

### Benchmarks reales - 50 Im√°genes SAR (1000x2000 px)

Los siguientes resultados fueron obtenidos procesando 50 im√°genes SAR con el pipeline completo:

| T√©cnica | Tiempo (s) | Speedup | Velocidad (img/s) | Im√°genes |
|---------|-----------|---------|-------------------|----------|
| Secuencial OpenCV | 18.60 | 1.00x | 2.69 | 50 |
| Pool (24 cores) | 10.23 | 1.82x | 4.89 | 50 |
| ThreadPool (24 threads) | 8.13 | 2.29x | 6.15 | 50 |
| MPI (12 cores) | 10.81 | 1.72x | 4.63 | 50 |
| CuPy GPU | 12.75 | 1.46x | 3.92 | 50 |

### An√°lisis de resultados

**üèÜ Mejor rendimiento:** ThreadPool (24 threads) - 2.29x speedup
- Aprovecha mejor el paralelismo a nivel de hilos para operaciones I/O intensivas
- Menor overhead de comunicaci√≥n entre hilos comparado con procesos

**ü•à Segundo lugar:** Pool (24 cores) - 1.82x speedup
- Buen balance entre rendimiento y simplicidad
- Mayor overhead por creaci√≥n de procesos

**ü•â Tercer lugar:** MPI (12 cores) - 1.72x speedup
- Excelente para procesamiento distribuido en clusters
- Escalabilidad lineal al agregar m√°s nodos

**üí° Nota sobre CuPy GPU (1.46x speedup):**
- El speedup relativamente bajo se debe a:
  - Overhead de transferencia CPU ‚Üî GPU
  - Im√°genes de tama√±o moderado (1000x2000 px)
  - Pipeline con muchas operaciones secuenciales
- CuPy GPU es m√°s eficiente con:
  - Im√°genes muy grandes (>4000x4000 px)
  - Procesamiento de muchas im√°genes en batch
  - Operaciones matem√°ticas intensivas

**Hardware utilizado:**
- **CPU:** AMD Ryzen 9 5900X (12 cores / 24 threads)
- **RAM:** 32 GB
- **GPU:** NVIDIA GeForce RTX 4070 Ti Super (16 GB VRAM)
- **Almacenamiento:** SSD NVMe 2 TB
- **Tama√±o de imagen:** 1000x2000 p√≠xeles (fijo)
- **Pipeline:** 7 etapas de procesamiento por imagen

*Nota: Los valores pueden variar seg√∫n el hardware utilizado. ThreadPool muestra el mejor rendimiento en este caso espec√≠fico debido a la naturaleza I/O intensiva del procesamiento de im√°genes con OpenCV.*

---

## ‚ö†Ô∏è Soluci√≥n de problemas

### Error: MPI no encontrado
```bash
sudo apt-get install openmpi-bin libopenmpi-dev
pip install mpi4py
```

### Error: CuPy no puede encontrar CUDA

**S√≠ntoma:**
```python
ImportError: libcudart.so.12: cannot open shared object file: No such file or directory
```

**Causa:** CUDA Toolkit no est√° instalado o no est√° en el PATH.

**Soluci√≥n 1 - Instalar CUDA Toolkit mediante Conda (Recomendado):**
```bash
conda activate parallel-sar-processor
conda install -c nvidia cuda-toolkit=12.6
```

**Soluci√≥n 2 - Verificar instalaci√≥n existente:**
```bash
# Verificar que CUDA est√© instalado
nvcc --version

# Si est√° instalado pero no se encuentra, agregar al PATH
export PATH=/usr/local/cuda-12.6/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-12.6/lib64:$LD_LIBRARY_PATH

# Hacer permanente agregando a ~/.bashrc
echo 'export PATH=/usr/local/cuda-12.6/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.6/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

**Soluci√≥n 3 - Verificar versi√≥n de CuPy:**
```bash
# Verificar versi√≥n de CUDA instalada
nvcc --version

# Reinstalar CuPy para la versi√≥n correcta de CUDA
pip uninstall cupy-cuda12x

# Para CUDA 11.x
pip install cupy-cuda11x

# Para CUDA 12.x
pip install cupy-cuda12x
```

### Error: CuPy instalado pero no detecta GPU

**S√≠ntoma:**
```python
CuPyException: CUDA environment is not correctly set up
```

**Diagn√≥stico:**
```bash
# Verificar que nvidia-smi funcione
nvidia-smi

# Verificar que el driver NVIDIA est√© cargado
lsmod | grep nvidia

# Probar importar CuPy y ver el error espec√≠fico
python -c "import cupy as cp; print(cp.cuda.runtime.getDeviceCount())"
```

**Soluci√≥n:**
```bash
# Si nvidia-smi no funciona, reinstalar driver NVIDIA
sudo ubuntu-drivers autoinstall
sudo reboot

# Si el driver funciona pero CuPy no, reinstalar CUDA Toolkit
conda install -c nvidia cuda-toolkit=12.6 --force-reinstall
```

### Error: Memoria insuficiente en GPU

**S√≠ntoma:**
```
cupy.cuda.memory.OutOfMemoryError: Out of memory allocating XXX bytes
```

**Soluciones:**

1. **Reducir tama√±o de imagen:**
```python
# En los scripts de procesamiento
tamanio_fijo = (800, 1600)  # Reducir de (1000, 2000)
```

2. **Liberar memoria GPU manualmente:**
```python
import cupy as cp
# Despu√©s de procesar cada imagen
cp.get_default_memory_pool().free_all_blocks()
```

3. **Verificar memoria disponible:**
```bash
nvidia-smi
# Buscar la columna "Memory-Usage"
```

4. **Cerrar otros procesos que usen GPU:**
```bash
# Ver procesos que usan GPU
nvidia-smi

# Si hay otros procesos, cerrarlos o reducir su uso
```

### Error: Timeout en descarga de dataset

Si `make download-dataset` falla, descargar manualmente desde:
```
https://drive.google.com/file/d/1vNYzal2fUyaZO5zwFmWgquj6f8ghLzab/view
```
Y extraer en el directorio `dataset/`.

### Error: ImportError al ejecutar scripts con MPI

**S√≠ntoma:**
```
ImportError: No module named 'mpi4py'
```

**Soluci√≥n:**
```bash
# Asegurarse de que mpi4py est√© instalado en el entorno
conda activate parallel-sar-processor
pip install mpi4py

# Si persiste, reinstalar desde conda
conda install -c conda-forge mpi4py
```

### Advertencia: Driver NVIDIA vs CUDA Toolkit

**Es importante entender la diferencia:**

- **Driver NVIDIA**: Software a nivel de sistema que permite comunicaci√≥n con la GPU
  - Se instala a nivel de sistema (requiere sudo)
  - Compatible con m√∫ltiples versiones de CUDA
  - Verifica con: `nvidia-smi`

- **CUDA Toolkit**: Librer√≠as y herramientas de desarrollo CUDA
  - Puede instalarse por usuario (conda) o sistema (sudo)
  - Debe ser compatible con el driver instalado
  - Verifica con: `nvcc --version`

**Compatibilidad Driver-CUDA:**
- Driver ‚â• 525.60.13 ‚Üí soporta CUDA 12.x
- Driver ‚â• 450.80.02 ‚Üí soporta CUDA 11.x

```bash
# Ver versi√≥n m√°xima de CUDA soportada por el driver
nvidia-smi
# Buscar "CUDA Version: X.X" en la esquina superior derecha
```

---

## üìö Dependencias principales

| Librer√≠a | Versi√≥n | Prop√≥sito |
|----------|---------|-----------|
| opencv-python | 4.12.0.88 | Procesamiento de im√°genes |
| numpy | 2.2.6 | Operaciones num√©ricas |
| pandas | 2.3.2 | An√°lisis de datos |
| matplotlib | 3.10.6 | Visualizaci√≥n |
| seaborn | 0.13.2 | Gr√°ficos estad√≠sticos |
| mpi4py | 4.1.0 | Procesamiento distribuido MPI |
| cupy-cuda12x | 13.6.0 | Procesamiento GPU |
| gdown | 5.2.0 | Descarga desde Google Drive |

---

## üë§ Autor

Proyecto desarrollado por Jorge Ceferino Valdez.

---

## üìÑ Licencia

Este proyecto es con fines acad√©micos para el curso mencionado.
